{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJB00R7knaOw"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai==1.* rank-bm25 pandas pillow pymupdf tqdm rouge nltk\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "import os, shutil, subprocess\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "os\n",
        "client = OpenAI(api_key=\"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\")\n",
        "CSV_PATH  = Path(\"/content/rule_presence_qa.csv\")\n",
        "IMG_DIR   = Path(\"/content/presence_images\")\n",
        "REPO_DIR  = Path(\"/content/design_qa\")\n",
        "RULE_PDF  = Path(\"/content/FSAE_Rules_2024.pdf\")\n",
        "\n",
        "if not IMG_DIR.exists() or len(list(IMG_DIR.glob(\"*\"))) == 0:\n",
        "    if REPO_DIR.exists():\n",
        "        shutil.rmtree(REPO_DIR)\n",
        "    subprocess.run([\"git\",\"clone\",\"-q\",\"--depth\",\"1\",\n",
        "                    \"https://github.com/anniedoris/design_qa.git\",\n",
        "                    str(REPO_DIR)], check=True)\n",
        "    IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    subprocess.run([\"bash\",\"-lc\", f\"cp -r {REPO_DIR}/dataset/rule_comprehension/rule_presence_qa/* {IMG_DIR}/\"], check=True)\n",
        "\n",
        "# Count images\n",
        "n_imgs = sum(len(list(IMG_DIR.glob(ext))) for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\"))\n",
        "print(\"Images ready:\", n_imgs)\n",
        "if not CSV_PATH.exists():\n",
        "    print(\"Downloading Presence CSV (RAW)…\")\n",
        "    subprocess.run([\"wget\",\"-q\",\"-O\",str(CSV_PATH),\n",
        "                    \"https://raw.githubusercontent.com/anniedoris/design_qa/main/dataset/rule_comprehension/rule_presence_qa.csv\"],\n",
        "                    check=True)\n",
        "\n",
        "assert CSV_PATH.exists() and CSV_PATH.stat().st_size > 0, \"Presence CSV missing/empty.\"\n",
        "with open(CSV_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    head = f.read(512).lower()\n",
        "assert \"<html\" not in head, \"Presence CSV looks like HTML/404. Re-download RAW CSV.\"\n",
        "if not RULE_PDF.exists():\n",
        "    candidates = list(Path(\"/content\").glob(\"FSAE*.pdf\"))\n",
        "    if candidates:\n",
        "        os.replace(str(candidates[0]), str(RULE_PDF))\n",
        "    else:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(\"Upload the FSAE Rules PDF (optional, improves RAG).\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                up_name = list(uploaded.keys())[0]\n",
        "                os.replace(up_name, RULE_PDF)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "print(\"CSV:\", CSV_PATH.exists(), \"PDF:\", RULE_PDF.exists(), \"REPO:\", REPO_DIR.exists())\n",
        "\n",
        "import io, re, textwrap, base64, time, json, importlib.util\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Paths\n",
        "IMG_ROOT  = IMG_DIR\n",
        "PRED_CSV  = Path(\"/content/presence_predictions.csv\")\n",
        "SCORE_TXT = Path(\"/content/presence_score.txt\")\n",
        "MODEL        = \"gpt-4o-mini\"\n",
        "MAX_SIDE     = 640\n",
        "JPEG_QUALITY = 80\n",
        "TEMPERATURE  = 0.0\n",
        "MAX_TOKENS   = 2\n",
        "CALL_DELAY   = 0.35\n",
        "SAVE_EVERY   = 10\n",
        "START_IDX    = 0\n",
        "FORCE_RERUN  = True\n",
        "assert CSV_PATH.exists() and CSV_PATH.stat().st_size > 0, \"CSV missing or empty.\"\n",
        "with open(CSV_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    head = f.read(512).lower()\n",
        "assert \"<html\" not in head, \"CSV looks like HTML/404. Re-download RAW CSV.\"\n",
        "assert IMG_ROOT.exists(), f\"Images folder missing: {IMG_ROOT}\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "required = {\"question\",\"image\",\"ground_truth\"}\n",
        "assert required.issubset(df.columns), f\"CSV must have columns: {required}\"\n",
        "try:\n",
        "    import fitz\n",
        "    HAVE_PYMUPDF = True\n",
        "except Exception:\n",
        "    HAVE_PYMUPDF = False\n",
        "\n",
        "def build_bm25_from_pdf(pdf_path: Path):\n",
        "    if not HAVE_PYMUPDF or not pdf_path.exists():\n",
        "        return None, []\n",
        "    paras = []\n",
        "    doc = fitz.open(str(pdf_path))\n",
        "    for page in doc:\n",
        "        text = page.get_text(\"text\")\n",
        "        for blk in re.split(r\"\\n\\s*\\n\", text):\n",
        "            s = \" \".join(blk.strip().split())\n",
        "            if len(s) >= 40:\n",
        "                paras.append(s)\n",
        "    if not paras:\n",
        "        return None, []\n",
        "    return BM25Okapi([p.lower().split() for p in paras]), paras\n",
        "\n",
        "BM25, PDF_PARAS = build_bm25_from_pdf(RULE_PDF)\n",
        "print(f\"[RAG] PDF exists: {RULE_PDF.exists()} | paragraphs indexed: {len(PDF_PARAS)} | BM25: {'ON' if BM25 else 'OFF'}\")\n",
        "\n",
        "def get_short_ctx(q: str, k: int = 2, limit: int = 300) -> str:\n",
        "    if not BM25:\n",
        "        return \"\"\n",
        "    toks = q.lower().split() + [\"visibility\", \"component\", \"rule\"]\n",
        "    hits = BM25.get_top_n(toks, PDF_PARAS, n=k)\n",
        "    if not hits: return \"\"\n",
        "    ctx = \" \".join(hits)\n",
        "    return textwrap.shorten(ctx, width=limit, placeholder=\"…\")\n",
        "\n",
        "SYSTEM_PROMPT = \"You are an FSAE visual judge. Reply with only one token: Yes or No.\"\n",
        "\n",
        "def downscale_to_b64(img_path: Path, max_side=MAX_SIDE, quality=JPEG_QUALITY) -> str:\n",
        "    with Image.open(img_path).convert(\"RGB\") as im:\n",
        "        w, h = im.size\n",
        "        s = max_side / max(w, h)\n",
        "        if s < 1.0:\n",
        "            im = im.resize((int(w*s), int(h*s)))\n",
        "        buf = io.BytesIO()\n",
        "        im.save(buf, format=\"JPEG\", quality=quality)\n",
        "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "def ask_yesno(image_b64: str, question: str, ctx: str) -> str:\n",
        "    user_txt = f\"Question: {question}\\n\" + (f\"Context: {ctx}\\n\" if ctx else \"\") + \"Answer Yes or No only.\"\n",
        "    msgs = [\n",
        "        {\"role\":\"system\",\"content\":SYSTEM_PROMPT},\n",
        "        {\"role\":\"user\",\"content\":[\n",
        "            {\"type\":\"text\",\"text\":user_txt},\n",
        "            {\"type\":\"image_url\",\"image_url\":{\"url\": f\"data:image/jpeg;base64,{image_b64}\"}}\n",
        "        ]}\n",
        "    ]\n",
        "    r = client.chat.completions.create(\n",
        "        model=MODEL, messages=msgs, temperature=TEMPERATURE, max_tokens=MAX_TOKENS, timeout=60\n",
        "    )\n",
        "    a = (r.choices[0].message.content or \"\").strip().lower()\n",
        "    if a.startswith(\"y\"): return \"Yes\"\n",
        "    if a.startswith(\"n\"): return \"No\"\n",
        "    return \"No\"\n",
        "preds, confs, expls = [], [], []\n",
        "if FORCE_RERUN:\n",
        "    preds, confs, expls = [], [], []\n",
        "    if PRED_CSV.exists():\n",
        "        try:\n",
        "            PRED_CSV.unlink()\n",
        "            print(\"[i] FORCE_RERUN=True → deleted old predictions CSV\")\n",
        "        except Exception as e:\n",
        "            print(\"[warn] could not delete old CSV:\", e)\n",
        "while len(preds) < len(df): preds.append(\"\")\n",
        "while len(confs) < len(df): confs.append(0.0)\n",
        "while len(expls) < len(df): expls.append(\"\")\n",
        "\n",
        "\n",
        "for i in tqdm(range(START_IDX, len(df)), total=len(df)-START_IDX):\n",
        "    row = df.iloc[i]\n",
        "    img_path = IMG_ROOT / str(row[\"image\"])\n",
        "    if not img_path.exists():\n",
        "        img_path = Path(str(row[\"image\"]))\n",
        "    if not img_path.exists():\n",
        "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "    b64 = downscale_to_b64(img_path)\n",
        "    q   = str(row[\"question\"])\n",
        "    ctx = get_short_ctx(q)\n",
        "\n",
        "    try:\n",
        "        ans = ask_yesno(b64, q, ctx)\n",
        "    except Exception:\n",
        "        time.sleep(1.2)\n",
        "        try:\n",
        "            ans = ask_yesno(b64, q, ctx)\n",
        "        except Exception as e2:\n",
        "            ans = \"No\"\n",
        "\n",
        "    preds[i] = ans\n",
        "    confs[i] = 0.0\n",
        "    expls[i] = \"\"\n",
        "\n",
        "    if ((i+1) % SAVE_EVERY == 0) or (i+1 == len(df)):\n",
        "        out = df.copy()\n",
        "        out[\"prediction\"]  = preds\n",
        "        out[\"confidence\"]  = confs\n",
        "        out[\"explanation\"] = expls\n",
        "        out.to_csv(PRED_CSV, index=False)\n",
        "\n",
        "    time.sleep(CALL_DELAY)\n",
        "\n",
        "out = df.copy()\n",
        "out[\"prediction\"]  = preds\n",
        "out[\"confidence\"]  = confs\n",
        "out[\"explanation\"] = expls\n",
        "out.to_csv(PRED_CSV, index=False)\n",
        "\n",
        "gt = out[\"ground_truth\"].astype(str).str.strip().str.lower().replace(\n",
        "    {\"y\":\"yes\",\"true\":\"yes\",\"n\":\"no\",\"false\":\"no\"})\n",
        "pr = out[\"prediction\"].astype(str).str.strip().str.lower()\n",
        "acc = (gt==pr).mean()\n",
        "\n",
        "with open(SCORE_TXT,\"w\") as f:\n",
        "    f.write(f\"Presence (ACC): {acc:.3f}\\n\")\n",
        "    f.write(f\"Rows: {len(out)}\\n\")\n",
        "    f.write(f\"Pred file: {PRED_CSV}\\n\")\n",
        "\n",
        "print(f\"[DONE] Presence-Lite ACC={acc:.3f}\")\n",
        "print(f\"Wrote: {PRED_CSV}  |  {SCORE_TXT}\")\n",
        "\n",
        "\n",
        "# Official Presence scoring (DesignQA metrics)\n",
        "\n",
        "import sys\n",
        "RESULTS_DIR = Path(\"/content/results\"); RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "if not REPO_DIR.exists():\n",
        "    subprocess.run([\"git\",\"clone\",\"-q\",\"https://github.com/anniedoris/design_qa.git\", str(REPO_DIR)], check=True)\n",
        "sys.path.append(str(REPO_DIR))\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"rouge\",\"nltk\"], check=True)\n",
        "import nltk; nltk.download('punkt', quiet=True)\n",
        "\n",
        "GT   = pd.read_csv(CSV_PATH).copy()\n",
        "PRED = pd.read_csv(PRED_CSV).copy()\n",
        "\n",
        "for col in [\"image\",\"answer\",\"label\",\"gt\",\"expected\",\"GroundTruth\",\"question\",\"ground_truth\"]:\n",
        "    if col in GT.columns: GT[col] = GT[col].astype(str)\n",
        "for col in [\"image\",\"prediction\",\"model_prediction\",\"reasoning\",\"explanation\"]:\n",
        "    if col in PRED.columns: PRED[col] = PRED[col].astype(str)\n",
        "\n",
        "from pathlib import Path as _P\n",
        "def _norm_png(x):\n",
        "    s = \"\" if pd.isna(x) else str(x).strip()\n",
        "    s = _P(s).name\n",
        "    if not s.lower().endswith(\".png\"):\n",
        "        s = f\"{s}.png\"\n",
        "    return s.lower()\n",
        "\n",
        "def pick_col(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns: return c\n",
        "    return None\n",
        "\n",
        "YES, NO, INS = \"Yes\", \"No\", \"INSUFFICIENT RULE EVIDENCE\"\n",
        "def _norm_truth(s: str) -> str:\n",
        "    t = (s or \"\").strip().lower()\n",
        "    if t.startswith(\"y\"): return YES\n",
        "    if t.startswith(\"n\"): return NO\n",
        "    if \"insufficient\" in t: return INS\n",
        "    return NO\n",
        "\n",
        "def _norm_pred(s: str) -> str:\n",
        "    t = (s or \"\").strip().lower()\n",
        "    if t.startswith(\"y\"): return YES\n",
        "    if t.startswith(\"n\"): return NO\n",
        "    if \"insufficient\" in t: return INS\n",
        "    return NO\n",
        "\n",
        "GT[\"image_norm\"] = GT.get(\"image\",\"\").apply(_norm_png)\n",
        "if \"image\" in PRED.columns:\n",
        "    PRED[\"image_norm\"] = PRED[\"image\"].apply(_norm_png)\n",
        "else:\n",
        "    PRED[\"image_norm\"] = \"\"\n",
        "if \"ground_truth\" not in GT.columns:\n",
        "    alt = pick_col(GT, [\"answer\",\"label\",\"gt\",\"expected\",\"GroundTruth\"])\n",
        "    if alt:\n",
        "        GT = GT.rename(columns={alt:\"ground_truth\"})\n",
        "    else:\n",
        "        raise KeyError(f\"No GT label column in GT. Columns={list(GT.columns)}\")\n",
        "if \"image_norm\" in PRED.columns and PRED[\"image_norm\"].str.len().gt(0).any():\n",
        "    J = GT.merge(PRED, on=\"image_norm\", how=\"inner\", suffixes=(\"_gt\",\"_pred\"))\n",
        "elif \"image\" in GT.columns and \"image\" in PRED.columns:\n",
        "    J = GT.merge(PRED, on=\"image\", how=\"inner\", suffixes=(\"_gt\",\"_pred\"))\n",
        "    J[\"image_norm\"] = J[\"image\"].apply(_norm_png)\n",
        "else:\n",
        "    print(\"[WARN] Aligning by row order (no reliable image key).\")\n",
        "    PRED = PRED.reindex(range(len(GT))).copy()\n",
        "    J = pd.concat([GT.reset_index(drop=True), PRED.reset_index(drop=True)], axis=1)\n",
        "    base_img_col = pick_col(J, [\"image_gt\",\"image\"])\n",
        "    if base_img_col is None:\n",
        "        raise KeyError(\"No image column found after fallback alignment.\")\n",
        "    J[\"image_norm\"] = J[base_img_col].apply(_norm_png)\n",
        "\n",
        "missing = len(GT) - len(J)\n",
        "if missing > 0:\n",
        "    print(f\"[WARN] {missing} GT rows had no matching prediction by image name.\")\n",
        "gt_col = pick_col(J, [\"ground_truth\",\"ground_truth_gt\",\"answer_gt\",\"label_gt\",\"gt_gt\",\"expected_gt\",\"GroundTruth_gt\",\n",
        "                      \"answer\",\"label\",\"gt\",\"expected\",\"GroundTruth\"])\n",
        "if gt_col is None:\n",
        "    raise KeyError(f\"Couldn't find ground truth column after merge. Columns={list(J.columns)}\")\n",
        "\n",
        "pred_col = \"model_prediction\" if \"model_prediction\" in J.columns else (\"prediction\" if \"prediction\" in J.columns else None)\n",
        "if pred_col is None:\n",
        "    raise KeyError(f\"Couldn't find prediction column after merge. Columns={list(J.columns)}\")\n",
        "\n",
        "J[\"_gt_norm\"]   = J[gt_col].map(_norm_truth)\n",
        "J[\"_pred_norm\"] = J[pred_col].map(_norm_pred)\n",
        "PRESENCE_EVAL = str(RESULTS_DIR / \"presence_eval_official.csv\")\n",
        "df_eval = pd.DataFrame({\n",
        "    \"ground_truth\": J[\"_gt_norm\"].astype(str),\n",
        "    \"model_prediction\": J[\"_pred_norm\"].astype(str),\n",
        "    \"explanation\": \"__\"\n",
        "})\n",
        "df_eval.to_csv(PRESENCE_EVAL, index=False)\n",
        "print(f\"[OK] Prepared official Presence eval CSV → {PRESENCE_EVAL}\")\n",
        "\n",
        "# Try repo metric\n",
        "try:\n",
        "    from eval.metrics.metrics import eval_presence_qa, eval_boolean_qa\n",
        "except Exception:\n",
        "    import importlib.util\n",
        "    metrics_py = REPO_DIR / \"eval\" / \"metrics\" / \"metrics.py\"\n",
        "    spec = importlib.util.spec_from_file_location(\"dq_metrics\", str(metrics_py))\n",
        "    dq = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(dq)\n",
        "    eval_presence_qa = getattr(dq, \"eval_presence_qa\", None)\n",
        "    eval_boolean_qa  = getattr(dq, \"eval_boolean_qa\", None)\n",
        "\n",
        "score = None\n",
        "if callable(eval_presence_qa):\n",
        "    try:\n",
        "        score = eval_presence_qa(PRESENCE_EVAL)\n",
        "        print(f\"[OK] eval_presence_qa: {score}\")\n",
        "    except Exception as e:\n",
        "        print(\"[warn] eval_presence_qa failed:\", e)\n",
        "\n",
        "if score is None and callable(eval_boolean_qa):\n",
        "    try:\n",
        "        score = eval_boolean_qa(PRESENCE_EVAL)\n",
        "        print(f\"[OK] eval_boolean_qa: {score}\")\n",
        "    except Exception as e:\n",
        "        print(\"[warn] eval_boolean_qa failed:\", e)\n",
        "\n",
        "# Final fallback: simple ACC\n",
        "if score is None:\n",
        "    acc2 = (df_eval[\"ground_truth\"].str.lower() == df_eval[\"model_prediction\"].str.lower()).mean()\n",
        "    score = acc2\n",
        "    print(f\"[fallback] Simple ACC: {acc2:.3f}\")\n",
        "\n",
        "with open(\"/content/presence.txt\", \"w\") as f:\n",
        "    f.write(\"DesignQA Results\\n\")\n",
        "    f.write(\"Subset: Presence\\n\")\n",
        "    f.write(f\"Num Questions: {len(J)}\\n\")\n",
        "    try:\n",
        "        f.write(f\"ACC: {float(score):.6f}\\n\")\n",
        "    except Exception:\n",
        "        f.write(f\"Score: {score}\\n\")\n",
        "\n",
        "print(\"Score file → /content/presence.txt\")\n"
      ]
    }
  ]
}